# -*- coding: utf-8 -*-
"""Model-CNN-EcoPlan

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DCt7lW71whp4Mry11fjQXb7e2Rdodp-e
"""

import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import cv2
import tensorflow as tf
import random
import shutil             # to copy images to another directory
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report , confusion_matrix

from tqdm import tqdm
from keras.layers import Conv2D, MaxPooling2D , BatchNormalization ,Dropout ,Flatten , Dense , Input , Rescaling , Resizing, GlobalAveragePooling2D
from keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from tensorflow.keras.applications import MobileNetV2

import warnings

with warnings.catch_warnings():
    warnings.simplefilter("ignore")

plt.style.use('ggplot')

import kagglehub

# Download latest version
path = kagglehub.dataset_download("mostafaabla/garbage-classification")

print("Path to dataset files:", path)

dataDirList = ['/root/.cache/kagglehub/datasets/mostafaabla/garbage-classification/versions/1/garbage_classification']

selectedClasses = ['battery' , 'biological', 'brown-glass', 'cardboard', 'clothes', 'green-glass', 'metal', 'paper', 'plastic', 'shoes', 'trash', 'white-glass']

imgPaths = []
labels = []
for dataDir in dataDirList:
    for className in os.listdir(dataDir):
        if className in selectedClasses :
            classPath = os.path.join(dataDir,className)
            for img in os.listdir(classPath):
                imgPath = os.path.join(classPath,img)
                imgPaths.append(imgPath)
                if className == 'white-glass':
                    className = 'glass'
                labels.append(className)

# Convert the 2 lists to dataframe to easy use
df = pd.DataFrame({
    'imgPath':imgPaths,
    'label':labels
})

df = df.sample(frac=1).reset_index(drop=True)            # Shuffle

df

# get the ratio such as 15% of each class for testing, 10% for validation, and 75% for training
def DataFrameSpliting(df , train_ratio , val_ratio , test_ratio , classesList):

    trainDf = pd.DataFrame(columns = ['imgPath','label'])
    valDf = pd.DataFrame(columns = ['imgPath','label'])
    testDf = pd.DataFrame(columns = ['imgPath','label'])

    for clas in classesList :
        tempDf = df[df['label'] == clas]
        train_end = int(len(tempDf) * train_ratio)
        val_end = int(len(tempDf) * (train_ratio + val_ratio))

        trainClassDf = tempDf[:train_end]
        valClassDf = tempDf[train_end:val_end]
        testClassDf = tempDf[val_end:]

        trainDf = pd.concat([trainDf , trainClassDf] , axis=0)
        valDf = pd.concat([valDf , valClassDf] , axis=0)
        testDf = pd.concat([testDf , testClassDf] , axis=0)

    return trainDf.sample(frac=1).reset_index(drop=True), valDf.sample(frac=1).reset_index(drop=True), testDf.sample(frac=1).reset_index(drop=True)

classList = list(df['label'].unique())
trainDf , valDf , testDf = DataFrameSpliting(df , 0.80 , 0.1 , 0.1 , classList)

trainDf['label'].value_counts()

valDf['label'].value_counts()

testDf['label'].value_counts()

imgPaths = df['imgPath']
fig, axs = plt.subplots(3, 8, figsize=(25, 10))

axs = axs.flatten()

for ax, imgPath in zip(axs , imgPaths):
    label = str(imgPath).split('/')[-2]    # extract label of an image from a path
    img = cv2.imread(imgPath)
    ax.imshow(img)
    ax.set_title(label)
    ax.axis('off')

plt.tight_layout()
plt.show()

datagenTrain = ImageDataGenerator(
            rescale=1./255,
            zoom_range=(1.0, 1.2),   # zoom in
            horizontal_flip=True,
            vertical_flip=True,
            rotation_range=45,
)

IMG_SIZE = (224,224)

trainGenerator = datagenTrain.flow_from_dataframe(
    trainDf ,
    x_col='imgPath',
    y_col='label',
    target_size=IMG_SIZE,
    batch_size=64 ,                    # Generate 64 image from the datagenTrain (flipped , rotated , zoomed , ....)  at once
    class_mode='categorical'
)

datagenVal = ImageDataGenerator( rescale=1./255 )

valGenerator = datagenVal.flow_from_dataframe(
    valDf ,
    x_col='imgPath',
    y_col='label',
    target_size=IMG_SIZE,
    batch_size=8 ,
    class_mode='categorical',
    shuffle=False
)

datagenTest = ImageDataGenerator( rescale=1./255 )

testGenerator = datagenTest.flow_from_dataframe(
    testDf ,
    x_col='imgPath',
    y_col='label',
    target_size=IMG_SIZE,
    batch_size=8 ,
    class_mode='categorical',
    shuffle=False
)

print(f"Training set size: {trainGenerator.samples}")
print(f"Validation set size: {valGenerator.samples}")
print(f"Testing set size: {testGenerator.samples}")

with tf.device('/GPU:0'):          # to use GPU
    Model = Sequential([

        MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3)),

        GlobalAveragePooling2D(),

        Flatten(),                                     # because we ignore the flatten and dense layers when include_top = False

        Dense(64,activation='relu'),

        BatchNormalization(),

        Dropout(0.08),

        Dense(12 ,activation='softmax')
    ])

preTrainedModel = Model.layers[0]
for layer in preTrainedModel.layers[:-4]:           # freez all layers except the first and last 3 layers, we will make them trainable (weghts changes with training)
    layer.trainable = False

Model.compile(optimizer='adam',loss='categorical_crossentropy' ,metrics=['accuracy'])

history = Model.fit(trainGenerator,
                    validation_data = valGenerator,
                    epochs=50,
                    verbose=1,
                    callbacks=[tf.keras.callbacks.EarlyStopping(
                                       patience=4,
                                       monitor='val_accuracy',
                                       restore_best_weights=True)])

Model.summary()

# Get training and validation accuracies
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

# Get number of epochs
epochs = range(len(acc))

fig, ax = plt.subplots(1, 2, figsize=(10, 5))
fig.suptitle('Training and validation accuracy')

for i, (data, label) in enumerate(zip([(acc, val_acc), (loss, val_loss)], ["Accuracy", "Loss"])):
    ax[i].plot(epochs, data[0], 'r', label="Training " + label)
    ax[i].plot(epochs, data[1], 'b', label="Validation " + label)
    ax[i].legend()
    ax[i].set_xlabel('epochs')

plt.show()

predictions = Model.predict(testGenerator)

trainGenerator.class_indices

test_loss, test_accuracy = Model.evaluate(testGenerator)
test_accuracy

trueClasses = testGenerator.classes
trueClasses[:10]

predictedClasses = predictions.argmax(axis=-1)
predictedClasses[:10]

ClassificationReport = classification_report(trueClasses, predictedClasses)
print('Classification Report is : \n', ClassificationReport )

# Import tambahan
import numpy as np

# Fungsi tambahan
def preprocess_image(img_path, img_size=(224, 224)):
    """
    Preprocess an image for prediction.
    :param img_path: Path to the image file
    :param img_size: Target size for resizing (default to match model input size)
    :return: Preprocessed image array
    """
    # Load image and resize
    img = tf.keras.preprocessing.image.load_img(img_path, target_size=img_size)
    # Convert image to array
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    # Preprocess image using MobileNetV2's preprocess_input
    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)
    # Expand dimensions to add batch size
    img_array = np.expand_dims(img_array, axis=0)
    return img_array

def predict_image(model, img_path, class_names):
    """
    Predict the class of a single image.
    :param model: Trained model
    :param img_path: Path to the image file
    :param class_names: List of class names
    :return: Predicted class and confidence score
    """
    # Preprocess the image
    img_array = preprocess_image(img_path, img_size=(224, 224))
    # Perform prediction
    predictions = model.predict(img_array, verbose=0)
    # For multi-class classification, get the class with the highest probability
    predicted_class_idx = np.argmax(predictions, axis=-1)[0]
    confidence = predictions[0][predicted_class_idx]
    predicted_class = class_names[predicted_class_idx]
    return predicted_class, confidence

def visualize_prediction(img_path, predicted_class, confidence, true_label):
    """
    Display the image with predicted and actual labels.
    :param img_path: Path to the image
    :param predicted_class: Predicted class label
    :param confidence: Confidence score
    :param true_label: Actual class label provided by the user
    """
    # Load and display the image
    img = tf.keras.preprocessing.image.load_img(img_path)
    plt.imshow(img)
    plt.title(
        f"Predicted: {predicted_class} ({confidence * 100:.2f}%)\n"
        f"Actual: {true_label}\n"
        f"Match: {'Akurat' if predicted_class.lower() == true_label.lower() else 'Tidak Akurat'}"
    )
    plt.axis("off")
    plt.show()

# Contoh penggunaan
class_names = list(trainGenerator.class_indices.keys())  # Ambil class names dari trainGenerator
print("Class Names:", class_names)

# Path ke gambar uji
test_img_path = "/content/baju-bekas.jpg"  # Sesuaikan dengan path gambar Anda

# Prediksi gambar
predicted_class, confidence = predict_image(Model, test_img_path, class_names)

# Input kategori asli dari pengguna
true_label = input("Masukkan kategori asli dari gambar: ")

# Tampilkan hasil perbandingan
visualize_prediction(test_img_path, predicted_class, confidence, true_label)